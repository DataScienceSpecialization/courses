<!DOCTYPE html>
<html>
<head>
  <title>Binomial Proportions</title>
  <meta charset="utf-8">
  <meta name="description" content="Binomial Proportions">
  <meta name="author" content="Brian Caffo, PhD">
  <meta name="generator" content="slidify" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <link rel="stylesheet" href="../../libraries/frameworks/io2012/css/default.css" media="all" >
  <link rel="stylesheet" href="../../libraries/frameworks/io2012/phone.css" 
    media="only screen and (max-device-width: 480px)" >
  <link rel="stylesheet" href="../../libraries/frameworks/io2012/css/slidify.css" >
  <link rel="stylesheet" href="../../libraries/highlighters/highlight.js/css/tomorrow.css" />
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
  <script data-main="../../libraries/frameworks/io2012/js/slides" 
    src="../../libraries/frameworks/io2012/js/require-1.0.8.min.js">
  </script>
  
    <link rel="stylesheet" href = "../../assets/css/custom.css">
<link rel="stylesheet" href = "../../assets/css/ribbons.css">

</head>
<body style="opacity: 0">
  <slides class="layout-widescreen">
    
    <!-- LOGO SLIDE -->
    <!-- END LOGO SLIDE -->
    

    <!-- TITLE SLIDE -->
    <!-- Should I move this to a Local Layout File? -->
    <slide class="title-slide segue nobackground">
      <aside class="gdbar">
        <img src="../../assets/img/bloomberg_shield.png">
      </aside>
      <hgroup class="auto-fadein">
        <h1>Binomial Proportions</h1>
        <h2>Mathematical Biostatistics Boot Camp</h2>
        <p>Brian Caffo, PhD<br/>Johns Hopkins Bloomberg School of Public Health</p>
      </hgroup>
          </slide>

    <!-- SLIDES -->
      <slide class="" id="slide-1" style="background:;">
  <hgroup>
    <h2>Table of contents</h2>
  </hgroup>
  <article>
    <ol>
<li>Intervals for binomial proportions</li>
<li>Agresti- Coull interval</li>
<li>Bayesian analysis

<ul>
<li>Prior specification</li>
<li>Posterior</li>
<li>Credible intervals</li>
</ul></li>
<li>Summary</li>
</ol>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-2" style="background:;">
  <hgroup>
    <h2>Intervals for binomial parameters</h2>
  </hgroup>
  <article>
    <ul>
<li><p>When \(X\sim\mbox{Binomial}(n, p)\) we know that</p>

<p>a. \(\hat p = X / n\) is the MLE for \(p\)
b. \(E[\hat p] = p\)
c. \(Var(\hat p) = p (1 - p) / n\)
d.  \[
  \frac{\hat p - p}{\sqrt{\hat p (1- \hat p)/n}}
  \]
follows a normal distribution for large \(n\)</p></li>
<li><p>The latter fact leads to the Wald interval for \(p\)
\[
\hat p \pm Z_{1-\alpha/2} \sqrt{\hat p (1 - \hat p) / n}
\]</p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-3" style="background:;">
  <hgroup>
    <h2>Some discussion</h2>
  </hgroup>
  <article>
    <ul>
<li>The Wald interval performs terribly</li>
<li><p>Coverage probability varies wildly, sometimes being quite low for certain values of \(n\) even when \(p\) is not near the boundaries</p>

<ul>
<li>Example, when \(p=.5\) and \(n=40\) the actual coverage of a \(95\%\) interval is only \(92\%\)</li>
</ul></li>
<li><p>When \(p\) is small or large, coverage can be quite poor even for extremely large values of \(n\)</p>

<ul>
<li>Example, when \(p=.005\) and \(n=1,876\) the actual coverage rate of a \(95\%\) interval is only \(90\%\)</li>
</ul></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-4" style="background:;">
  <hgroup>
    <h2>Simple fix</h2>
  </hgroup>
  <article>
    <ul>
<li>A simple fix for the problem is to add two successes and two failures</li>
<li>That is let \(\tilde p = (X + 2) / (n + 4)\)</li>
<li>The (Agresti- Coull) interval is 
\[
\tilde p \pm Z_{1-\alpha/2} \sqrt{\tilde p (1 - \tilde p) / \tilde n}
\]</li>
<li>Motivation: when \(p\) is large or small, the distribution of \(\hat p\) is skewed and it does not make sense to center the interval at the MLE; adding the pseudo observations pulls the center of the interval toward \(.5\)</li>
<li>Later we will show that this interval is the inversion of a hypothesis testing technique</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-5" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <p>Suppose that in a random sample of an at-risk population \(13\) of \(20\) subjects had hypertension. Estimate the prevalence of hypertension in this population.</p>

<ul>
<li> \(\hat p = .65\),  \(n = 20\)</li>
<li> \(\tilde p = .63\), \(\tilde n = 24\)</li>
<li> \(Z_{.975} = 1.96\)</li>
<li> Wald interval \([.44, .86]\)</li>
<li> Agresti-Coull interval \([.44, .82]\) </li>
<li> \(1/8\) likelihood interval \([.42, .84]\)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-6" style="background:;">
  <hgroup>
    
  </hgroup>
  <article>
    <p><img class="center" src="../assets/binomialLikelihoodExample.png" height=500></p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-7" style="background:;">
  <hgroup>
    <h2>Bayesian analysis</h2>
  </hgroup>
  <article>
    <ul>
<li>Bayesian statistics posits a <strong>prior</strong> on the parameter of interest</li>
<li>All inferences are then performed on the distribution of the parameter given the data, called the <strong>posterior</strong></li>
<li>In general,
\[
\mbox{Posterior} \propto \mbox{Likelihood} \times \mbox{Prior}
\]</li>
<li>Therefore (as we saw in diagnostic testing) the likelihood is the factor by which our prior beliefs are updated to produce conclusions in the light of the data</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-8" style="background:;">
  <hgroup>
    <h2>Beta priors</h2>
  </hgroup>
  <article>
    <ul>
<li>The beta distribution is the default prior for parameters between \(0\) and \(1\).
\item The beta density depends on two parameters \(\alpha\) and \(\beta\)
\[
\frac{\Gamma(\alpha +  \beta)}{\Gamma(\alpha)\Gamma(\beta)}
p ^ {\alpha - 1} (1 - p) ^ {\beta - 1} ~~~~\mbox{for} ~~ 0 \leq p \leq 1
\]</li>
<li>The mean of the beta density is \(\alpha / (\alpha + \beta)\)</li>
<li>The variance of the beta density is \
\[\frac{\alpha \beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)}\]</li>
<li>The uniform density is the special case where \(\alpha = \beta = 1\)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-9" style="background:;">
  <hgroup>
    
  </hgroup>
  <article>
    <p><img class="center" src="../assets/beta.png" height=500></p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-10" style="background:;">
  <hgroup>
    <h2>Posterior</h2>
  </hgroup>
  <article>
    <ul>
<li>Suppose that we chose values of \(\alpha\) and \(\beta\) so that the beta prior is indicative of our degree of belief regarding \(p\) in the absence of data
\item Then using the rule that
\[
\mbox{Posterior} \propto \mbox{Likelihood} \times \mbox{Prior}
\]
and throwing out anything that doesn&#39;t depend on \(p\), we have that
\[
\begin{eqnarray*}
\mbox{Posterior} &\propto & p^x(1 - p)^{n-x} \times p^{\alpha -1} (1 - p)^{\beta - 1} \\
             &  =     & p^{x + \alpha - 1} (1 - p)^{n - x + \beta - 1}
\end{eqnarray*}
\]</li>
<li>This density is just another beta density with parameters \(\tilde \alpha = x + \alpha\) and \(\tilde \beta = n - x + \beta\)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-11" style="background:;">
  <hgroup>
    <h2>Posterior mean</h2>
  </hgroup>
  <article>
    <p>\[
 \begin{eqnarray*}
E[p ~|~ X] & = &  \frac{\tilde \alpha}{\tilde \alpha + \tilde \beta}\\ \\
& = & \frac{x + \alpha}{x + \alpha + n - x + \beta}\\ \\
& = & \frac{x + \alpha}{n + \alpha + \beta} \\ \\
& = & \frac{x}{n} \times \frac{n}{n + \alpha + \beta} + \frac{\alpha}{\alpha + \beta} \times \frac{\alpha + \beta}{n + \alpha + \beta} \\ \\
& = & \mbox{MLE} \times \pi + \mbox{Prior Mean} \times (1 - \pi)
  \end{eqnarray*}
\]</p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-12" style="background:;">
  <hgroup>
    
  </hgroup>
  <article>
    <ul>
<li>The posterior mean is a mixture of the MLE (\(\hat p\)) and the prior mean</li>
<li>\(\pi\) goes to \(1\) as \(n\) gets large; for large \(n\) the data swamps the prior</li>
<li>For small \(n\), the prior mean dominates </li>
<li>Generalizes how science should ideally work; as data becomes increasingly available, prior beliefs should matter less and less</li>
<li>With a prior that is degenerate at a value, no amount of data can overcome the prior</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-13" style="background:;">
  <hgroup>
    <h2>Posterior variance</h2>
  </hgroup>
  <article>
    <ul>
<li>The posterior variance is
\[
\begin{eqnarray*}
Var(p ~|~ x) & = & \frac{\tilde \alpha \tilde \beta}%
{(\tilde \alpha + \tilde \beta)^2 (\tilde \alpha + \tilde \beta + 1)} \\ \\
& = & 
\frac{ (x + \alpha)(n - x + \beta)}%
{(n + \alpha + \beta)^2 (n + \alpha + \beta + 1)}
\end{eqnarray*}
\]</li>
<li>Let \(\tilde p = (x + \alpha) / (n + \alpha + \beta)\) and \(\tilde n = n + \alpha + \beta\) then we have
\[
Var(p ~|~ x) = \frac{\tilde p (1 - \tilde p)}{\tilde n + 1}
\]</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-14" style="background:;">
  <hgroup>
    <h2>Discussion</h2>
  </hgroup>
  <article>
    <ul>
<li>If \(\alpha = \beta = 2\) then the posterior mean is
\[
\tilde p = (x + 2) / (n + 4)
\]
and the posterior variance is 
\[
\tilde p (1 - \tilde p) / (\tilde n + 1)
\]</li>
<li>This is almost exactly the mean and variance we used for the Agresti-Coull interval</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-15" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <ul>
<li>Consider the previous example where \(x = 13\) and \(n=20\)</li>
<li>Consider a uniform prior, \(\alpha = \beta = 1\)</li>
<li>The posterior is proportional to (see formula above)
\[
p^{x + \alpha - 1} (1 - p)^{n - x + \beta - 1} = p^x (1 - p)^{n-x}
\]
that is, for the uniform prior, the posterior is the likelihood</li>
<li>Consider the instance where \(\alpha = \beta = 2\) (recall this prior is humped around the point \(.5\)) the posterior is
\[
p^{x + \alpha - 1} (1 - p)^{n - x + \beta - 1} = p^{x + 1} (1 - p)^{n-x + 1}
\]</li>
<li>The ``Jeffrey&#39;s prior&#39;&#39; which has some theoretical benefits puts \(\alpha = \beta = .5\)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-16" style="background:;">
  <hgroup>
    
  </hgroup>
  <article>
    <p><img class="center" src="../assets/binBayes1.png" height=500></p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-17" style="background:;">
  <hgroup>
    
  </hgroup>
  <article>
    <p><img class="center" src="../assets/binBayes2.png" height=500></p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-18" style="background:;">
  <hgroup>
    
  </hgroup>
  <article>
    <p><img class="center" src="../assets/binBayes3.png" height=500></p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-19" style="background:;">
  <hgroup>
    
  </hgroup>
  <article>
    <p><img class="center" src="../assets/binBayes4.png" height=500></p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-20" style="background:;">
  <hgroup>
    
  </hgroup>
  <article>
    <p><img class="center" src="../assets/binBayes5.png" height=500></p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-21" style="background:;">
  <hgroup>
    <h2>Bayesian credible intervals</h2>
  </hgroup>
  <article>
    <ul>
<li>A <em>Bayesian credible interval</em> is the  Bayesian analog of a confidence interval</li>
<li>A \(95\%\) credible interval, \([a, b]\) would satisfy
\[
P(p \in [a, b] ~|~ x) = .95
\]</li>
<li>The best credible intervals chop off the posterior with a horizontal line in the same way we did for likelihoods </li>
<li>These are called highest posterior density (HPD) intervals</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-22" style="background:;">
  <hgroup>
    
  </hgroup>
  <article>
    <p><img class="center" src="../assets/hpd.png" height=500></p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-23" style="background:;">
  <hgroup>
    <h2>R code</h2>
  </hgroup>
  <article>
    <p>Install the <code>binom</code> package, then the command</p>

<pre><code class="r">library(binom)
binom.bayes(13, 20, type = &quot;highest&quot;)
</code></pre>

<p>gives the HPD interval. The default credible level is \(95\%\) and the default prior is the Jeffrey&#39;s prior.</p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-24" style="background:;">
  <hgroup>
    <h2>Interpretation of confidence intervals</h2>
  </hgroup>
  <article>
    <ul>
<li>Confidence interval: (Wald) \([.44, .86]\)</li>
<li><p>Fuzzy interpretation: </p>

<p><em>We are 95% confident that \(p\) lies between \(.44\) to \(.86\)</em></p></li>
<li><p>Actual interpretation: </p>

<p><em>The interval \(.44\) to \(.86\) was constructed such that in repeated independent experiments, \(95\%\) of the intervals obtained would contain \(p\).</em></p></li>
<li><p>Yikes!</p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-25" style="background:;">
  <hgroup>
    <h2>Likelihood intervals</h2>
  </hgroup>
  <article>
    <ul>
<li>Recall the \(1/8\) likelihood interval was \([.42, .84]\)</li>
<li><p>Fuzzy interpretation:</p>

<p><em>The interval \([.42, .84]\) represents plausible values for \(p\).</em></p></li>
<li><p>Actual interpretation</p>

<p><em>The interval \([.42, .84]\) represents plausible values for \(p\) in the sense that for each point in this interval, there is no other point that is more than \(8\) times better supported given the data.</em></p></li>
<li><p>Yikes!</p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-26" style="background:;">
  <hgroup>
    <h2>Credible intervals</h2>
  </hgroup>
  <article>
    <ul>
<li>Recall that Jeffrey&#39;s prior \(95\%\) credible interval was \([.44, .84]\)</li>
<li><p>Actual interpretation</p>

<p><em>The probability that \(p\) is between \(.44\) and \(.84\) is \(95\%\).</em></p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

    <slide class="backdrop"></slide>
  </slides>

  <!--[if IE]>
    <script 
      src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js">  
    </script>
    <script>CFInstall.check({mode: 'overlay'});</script>
  <![endif]-->
</body>
<!-- Grab CDN jQuery, fall back to local if offline -->
<script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script>
<script>window.jQuery || document.write('<script src="../../libraries/widgets/quiz/js/jquery-1.7.min.js"><\/script>')</script>
<!-- Load Javascripts for Widgets -->
<!-- MathJax: Fall back to local if CDN offline but local image fonts are not supported (saves >100MB) -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<!-- <script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script> -->
<script>window.MathJax || document.write('<script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS":{imageFont:null}});<\/script><script src="../../libraries/widgets/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"><\/script>')
</script>
<!-- LOAD HIGHLIGHTER JS FILES -->
<script src="../../libraries/highlighters/highlight.js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<!-- DONE LOADING HIGHLIGHTER JS FILES -->
</html>