<!DOCTYPE html>
<html>
<head>
  <title>Bootstrapping</title>
  <meta charset="utf-8">
  <meta name="description" content="Bootstrapping">
  <meta name="author" content="Brian Caffo, PhD">
  <meta name="generator" content="slidify" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <link rel="stylesheet" href="../../libraries/frameworks/io2012/css/default.css" media="all" >
  <link rel="stylesheet" href="../../libraries/frameworks/io2012/phone.css" 
    media="only screen and (max-device-width: 480px)" >
  <link rel="stylesheet" href="../../libraries/frameworks/io2012/css/slidify.css" >
  <link rel="stylesheet" href="../../libraries/highlighters/highlight.js/css/tomorrow.css" />
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
  <script data-main="../../libraries/frameworks/io2012/js/slides" 
    src="../../libraries/frameworks/io2012/js/require-1.0.8.min.js">
  </script>
  
    <link rel="stylesheet" href = "../../assets/css/custom.css">
<link rel="stylesheet" href = "../../assets/css/ribbons.css">

</head>
<body style="opacity: 0">
  <slides class="layout-widescreen">
    
    <!-- LOGO SLIDE -->
    <!-- END LOGO SLIDE -->
    

    <!-- TITLE SLIDE -->
    <!-- Should I move this to a Local Layout File? -->
    <slide class="title-slide segue nobackground">
      <aside class="gdbar">
        <img src="../../assets/img/bloomberg_shield.png">
      </aside>
      <hgroup class="auto-fadein">
        <h1>Bootstrapping</h1>
        <h2>Mathematical Biostatistics Boot Camp</h2>
        <p>Brian Caffo, PhD<br/>Johns Hopkins Bloomberg School of Public Health</p>
      </hgroup>
          </slide>

    <!-- SLIDES -->
      <slide class="" id="slide-1" style="background:;">
  <hgroup>
    <h2>Table of contents</h2>
  </hgroup>
  <article>
    <ol>
<li>The jackknife</li>
<li>The bootstrap principle</li>
<li>The bootstrap</li>
</ol>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-2" style="background:;">
  <hgroup>
    <h2>The jackknife</h2>
  </hgroup>
  <article>
    <ul>
<li>The jackknife is a tool for estimating standard errors  and the bias of estimators </li>
<li>As its name suggests, the jackknife is a small, handy tool; in contrast to the bootstrap, which is then the moral equivalent of a giant workshop full of tools</li>
<li>Both the jackknife and the bootstrap involve <em>resampling</em> data; that is, repeatedly creating new data sets from the original data</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-3" style="background:;">
  <hgroup>
    <h2>The jackknife</h2>
  </hgroup>
  <article>
    <ul>
<li>The jackknife deletes each observation and calculates an estimate based on the remaining \(n-1\) of them</li>
<li>It uses this collection of estimates to do things like estimate the bias and the standard error</li>
<li>Note that estimating the bias and having a standard error are not needed for things like sample means, which we know are unbiased estimates of population means and what their standard errors are</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-4" style="background:;">
  <hgroup>
    <h2>The jackknife</h2>
  </hgroup>
  <article>
    <ul>
<li>We&#39;ll consider the jackknife for univariate data</li>
<li>Let \(X_1,\ldots,X_n\) be a collection of data used to estimate a parameter \(\theta\)</li>
<li>Let \(\hat \theta\) be the estimate based on the full data set</li>
<li>Let \(\hat \theta_{i}\) be the estimate of \(\theta\) obtained by <em>deleting observation \(i\)</em></li>
<li>Let \(\bar \theta = \frac{1}{n}\sum_{i=1}^n \hat \theta_{i}\)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-5" style="background:;">
  <hgroup>
    <h2>Continued</h2>
  </hgroup>
  <article>
    <ul>
<li>Then, the jackknife estimate of the bias is
\[
(n - 1) \left(\bar \theta - \hat \theta\right)
\]
(how far the average delete-one estimate is from the actual estimate)</li>
<li>The jackknife estimate of the standard error is
\[
\left[\frac{n-1}{n}\sum_{i=1}^n (\hat \theta_i - \bar\theta )^2\right]^{1/2}
\]
(the deviance of the delete-one estimates from the average delete-one estimate)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-6" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <ul>
<li>Consider the data set of \(630\) measurements of gray matter volume for workers from a lead manufacturing plant</li>
<li>The median gray matter volume is around 589 cubic centimeters</li>
<li>We want to estimate the bias and standard error of the median</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-7" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <p>The gist of the code</p>

<pre><code class="r">n &lt;- length(gmVol)
theta &lt;- median(gmVol)
jk &lt;- sapply(1 : n,
             function(i) median(gmVol[-i])
             )
thetaBar &lt;- mean(jk)
biasEst &lt;- (n - 1) * (thetaBar - theta) 
seEst &lt;- sqrt((n - 1) * mean((jk - thetaBar)^2))
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-8" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <p>Or, using the <code>bootstrap</code> package</p>

<pre><code class="r">library(bootstrap)
out &lt;- jackknife(gmVol, median)
out$jack.se
out$jack.bias
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-9" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <ul>
<li>Both methods (of course) yield an estimated bias of \(0\) and a se of \(9.94\)</li>
<li>Odd little fact: the jackknife estimate of the bias for the median is always \(0\) when the number of observations is even</li>
<li>It has been shown that the jackknife is a linear approximation to the bootstrap</li>
<li>Generally do not use the jackknife for sample quantiles like the median; as it has been shown to have some poor properties</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-10" style="background:;">
  <hgroup>
    <h2>Pseudo observations</h2>
  </hgroup>
  <article>
    <ul>
<li>Another interesting way to think about the jackknife uses pseudo observations</li>
<li>Let
\[
  \mbox{Pseudo Obs} = n \hat \theta - (n - 1) \hat \theta_{i}
\]</li>
<li>Think of these as ``whatever observation \(i\) contributes to the estimate of \(\theta\)&#39;&#39;</li>
<li>Note when \(\hat \theta\) is the sample mean, the pseudo observations are the data themselves</li>
<li>Then the sample standard error of these observations is the previous jackknife estimated standard error.</li>
<li>The mean of these observations is a bias-corrected estimate of \(\theta\)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-11" style="background:;">
  <hgroup>
    <h2>The bootstrap</h2>
  </hgroup>
  <article>
    <ul>
<li>The bootstrap is a tremendously useful tool for constructing confidence intervals and calculating standard errors for difficult statistics</li>
<li>For example, how would one derive a confidence interval for the median?</li>
<li>The bootstrap procedure follows from the so called bootstrap principle</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-12" style="background:;">
  <hgroup>
    <h2>The bootstrap principle</h2>
  </hgroup>
  <article>
    <ul>
<li>Suppose that I have a statistic that estimates some population parameter, but I don&#39;t know its sampling distribution</li>
<li>The bootstrap principle suggests using the distribution defined by the data to approximate its sampling distribution</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-13" style="background:;">
  <hgroup>
    <h2>The bootstrap in practice</h2>
  </hgroup>
  <article>
    <ul>
<li>In practice, the bootstrap principle is always carried out using simulation</li>
<li>We will cover only a few aspects of bootstrap resampling</li>
<li><p>The general procedure follows by first simulating complete data sets from the observed data with replacement</p>

<ul>
<li>This is approximately drawing from the sampling distribution of that statistic, at least as far as the data is able to approximate the true population distribution</li>
</ul></li>
<li><p>Calculate the statistic for each simulated data set</p></li>
<li><p>Use the simulated statistics to either define a confidence interval or take the standard deviation to calculate a standard error</p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-14" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <ul>
<li>Consider again, the data set of \(630\) measurements of gray matter volume for workers from a lead manufacturing plant</li>
<li>The median gray matter volume is around 589 cubic centimeters</li>
<li>We want a confidence interval for the median of these measurements</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-15" style="background:;">
  <hgroup>
    
  </hgroup>
  <article>
    <ul>
<li><p>Bootstrap procedure for calculating confidence interval for the median from a data set of \(n\) observations</p>

<p>i. Sample \(n\) observations <strong>with replacement</strong> from the observed data resulting in one simulated complete data set</p>

<p>ii. Take the median of the simulated data set</p>

<p>iii. Repeat these two steps \(B\) times, resulting in \(B\) simulated medians</p>

<p>iv. These medians are approximately drawn from the sampling distribution of the median of \(n\) observations; therefore we can</p>

<ul>
<li>Draw a histogram of them</li>
<li>Calculate their standard deviation to estimate the standard error of the median</li>
<li>Take the \(2.5^{th}\) and \(97.5^{th}\) percentiles as a confidence interval for the median</li>
</ul></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-16" style="background:;">
  <hgroup>
    <h2>Example code</h2>
  </hgroup>
  <article>
    <pre><code class="r">B &lt;- 1000
n &lt;- length(gmVol)
resamples &lt;- matrix(sample(gmVol,
                           n * B,
                           replace = TRUE),
                    B, n)
medians &lt;- apply(resamples, 1, median)
sd(medians)
[1] 3.148706
quantile(medians, c(.025, .975))
    2.5%    97.5% 
582.6384 595.3553 
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-17" style="background:;">
  <hgroup>
    
  </hgroup>
  <article>
    <p><img class="center" src="../assets/bootstrap.png" height=500></p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-18" style="background:;">
  <hgroup>
    <h2>Notes on the bootstrap</h2>
  </hgroup>
  <article>
    <ul>
<li>The bootstrap is non-parametric</li>
<li>However, the theoretical arguments proving the validity of the bootstrap rely on large samples</li>
<li>Better percentile bootstrap confidence intervals correct for bias</li>
<li>There are lots of variations on bootstrap procedures; the book &quot;An Introduction to the Bootstrap&quot;&quot; by Efron and Tibshirani is a great place to start for both bootstrap and jackknife information</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-19" style="background:;">
  <hgroup>
    
  </hgroup>
  <article>
    <pre><code class="r">library(boot)
stat &lt;- function(x, i) {median(x[i])}  
boot.out &lt;- boot(data = gmVol,
                 statistic = stat,
                 R = 1000)
boot.ci(boot.out)
Level     Percentile            BCa          
95%   (583.1, 595.2 )   (583.2, 595.3 ) 
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

    <slide class="backdrop"></slide>
  </slides>

  <!--[if IE]>
    <script 
      src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js">  
    </script>
    <script>CFInstall.check({mode: 'overlay'});</script>
  <![endif]-->
</body>
<!-- Grab CDN jQuery, fall back to local if offline -->
<script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script>
<script>window.jQuery || document.write('<script src="../../libraries/widgets/quiz/js/jquery-1.7.min.js"><\/script>')</script>
<!-- Load Javascripts for Widgets -->
<!-- MathJax: Fall back to local if CDN offline but local image fonts are not supported (saves >100MB) -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<!-- <script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script> -->
<script>window.MathJax || document.write('<script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS":{imageFont:null}});<\/script><script src="../../libraries/widgets/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"><\/script>')
</script>
<!-- LOAD HIGHLIGHTER JS FILES -->
<script src="../../libraries/highlighters/highlight.js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<!-- DONE LOADING HIGHLIGHTER JS FILES -->
</html>