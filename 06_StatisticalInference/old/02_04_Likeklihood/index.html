<!DOCTYPE html>
<html>
<head>
  <title>Likelihood</title>
  <meta charset="utf-8">
  <meta name="description" content="Likelihood">
  <meta name="author" content="Brian Caffo, Roger Peng, Jeff Leek">
  <meta name="generator" content="slidify" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <link rel="stylesheet" href="../../librariesNew/frameworks/io2012/css/default.css" media="all" >
  <link rel="stylesheet" href="../../librariesNew/frameworks/io2012/css/phone.css" 
    media="only screen and (max-device-width: 480px)" >
  <link rel="stylesheet" href="../../librariesNew/frameworks/io2012/css/slidify.css" >
  <link rel="stylesheet" href="../../librariesNew/highlighters/highlight.js/css/tomorrow.css" />
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->  
  
  <!-- Grab CDN jQuery, fall back to local if offline -->
  <script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../librariesNew/widgets/quiz/js/jquery.js"><\/script>')</script> 
  <script data-main="../../librariesNew/frameworks/io2012/js/slides" 
    src="../../librariesNew/frameworks/io2012/js/require-1.0.8.min.js">
  </script>
  
  

</head>
<body style="opacity: 0">
  <slides class="layout-widescreen">
    
    <!-- LOGO SLIDE -->
        <slide class="title-slide segue nobackground">
  <aside class="gdbar">
    <img src="../../assets/img/bloomberg_shield.png">
  </aside>
  <hgroup class="auto-fadein">
    <h1>Likelihood</h1>
    <h2>Statistical Inference</h2>
    <p>Brian Caffo, Roger Peng, Jeff Leek<br/>Johns Hopkins Bloomberg School of Public Health</p>
  </hgroup>
  <article></article>  
</slide>
    

    <!-- SLIDES -->
    <slide class="" id="slide-1" style="background:;">
  <hgroup>
    <h2>Likelihood</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>A common and fruitful approach to statistics is to assume that the data arises from a family of distributions indexed by a parameter that represents a useful summary of the distribution</li>
<li>The <strong>likelihood</strong> of a collection of data is the joint density evaluated as a function of the parameters with the data fixed</li>
<li>Likelihood analysis of data uses the likelihood to perform inference regarding the unknown parameter</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-2" style="background:;">
  <hgroup>
    <h2>Likelihood</h2>
  </hgroup>
  <article data-timings="">
    <p>Given a statistical probability mass function or density, say \(f(x, \theta)\), where \(\theta\) is an unknown parameter, the <strong>likelihood</strong> is \(f\) viewed as a function of \(\theta\) for a fixed, observed value of \(x\). </p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-3" style="background:;">
  <hgroup>
    <h2>Interpretations of likelihoods</h2>
  </hgroup>
  <article data-timings="">
    <p>The likelihood has the following properties:</p>

<ol>
<li>Ratios of likelihood values measure the relative evidence of one value of the unknown parameter to another.</li>
<li>Given a statistical model and observed data, all of the relevant information contained in the data regarding the unknown parameter is contained in the likelihood.</li>
<li>If \(\{X_i\}\) are independent random variables, then their likelihoods multiply.  That is, the likelihood of the parameters given all of the \(X_i\) is simply the product of the individual likelihoods.</li>
</ol>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-4" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Suppose that we flip a coin with success probability \(\theta\)</li>
<li>Recall that the mass function for \(x\)
\[
f(x,\theta) = \theta^x(1 - \theta)^{1 - x}  ~~~\mbox{for}~~~ \theta \in [0,1].
\]
where \(x\) is either \(0\) (Tails) or \(1\) (Heads) </li>
<li>Suppose that the result is a head</li>
<li>The likelihood is
\[
{\cal L}(\theta, 1) = \theta^1 (1 - \theta)^{1 - 1} = \theta  ~~~\mbox{for} ~~~ \theta \in [0,1].
\]</li>
<li>Therefore, \({\cal L}(.5, 1) / {\cal L}(.25, 1) = 2\), </li>
<li>There is twice as much evidence supporting the hypothesis that \(\theta = .5\) to the hypothesis that \(\theta = .25\)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-5" style="background:;">
  <hgroup>
    <h2>Example continued</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Suppose now that we flip our coin from the previous example 4 times and get the sequence 1, 0, 1, 1</li>
<li>The likelihood is:
\[
\begin{eqnarray*}
{\cal L}(\theta, 1,0,1,1) & = & \theta^1 (1 - \theta)^{1 - 1}
\theta^0 (1 - \theta)^{1 - 0}  \\
& \times & \theta^1 (1 - \theta)^{1 - 1} 
\theta^1 (1 - \theta)^{1 - 1}\\
& = &  \theta^3(1 - \theta)^1
\end{eqnarray*}
\]</li>
<li>This likelihood only depends on the total number of heads and the total number of tails; we might write \({\cal L}(\theta, 1, 3)\) for shorthand</li>
<li>Now consider \({\cal L}(.5, 1, 3) / {\cal L}(.25, 1, 3) = 5.33\)</li>
<li>There is over five times as much evidence supporting the hypothesis that \(\theta = .5\) over that \(\theta = .25\)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-6" style="background:;">
  <hgroup>
    <h2>Plotting likelihoods</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Generally, we want to consider all the values of \(\theta\) between 0 and 1</li>
<li>A <strong>likelihood plot</strong> displays \(\theta\) by \({\cal L}(\theta,x)\)</li>
<li>Because the likelihood measures <em>relative evidence</em>, dividing the curve by its maximum value (or any other value for that matter) does not change its interpretation</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-7" style="background:;">
  <article data-timings="">
    <pre><code class="r">pvals &lt;- seq(0, 1, length = 1000)
plot(pvals, dbinom(3, 4, pvals)/dbinom(3, 4, 3/4), type = &quot;l&quot;, frame = FALSE, 
    lwd = 3, xlab = &quot;p&quot;, ylab = &quot;likelihood / max likelihood&quot;)
</code></pre>

<p><img src="assets/fig/unnamed-chunk-1.png" alt="plot of chunk unnamed-chunk-1"> </p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-8" style="background:;">
  <hgroup>
    <h2>Maximum likelihood</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>The value of \(\theta\) where the curve reaches its maximum has a special meaning</li>
<li>It is the value of \(\theta\) that is most well supported by the data</li>
<li>This point is called the <strong>maximum likelihood estimate</strong> (or MLE) of \(\theta\)
\[
MLE = \mathrm{argmax}_\theta {\cal L}(\theta, x).
\]</li>
<li>Another interpretation of the MLE is that it is the value of \(\theta\) that would make the data that we observed most probable</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-9" style="background:;">
  <hgroup>
    <h2>Some results</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>\(X_1, \ldots, X_n \stackrel{iid}{\sim} N(\mu, \sigma^2)\) the MLE of \(\mu\) is \(\bar X\) and the ML of \(\sigma^2\) is the biased sample variance estimate.</li>
<li>If \(X_1,\ldots, X_n \stackrel{iid}{\sim} Bernoulli(p)\) then the MLE of \(p\) is \(\bar X\) (the sample proportion of 1s).</li>
<li>If \(X_i \stackrel{iid}{\sim} Binomial(n_i, p)\) then the MLE of \(p\) is \(\frac{\sum_{i=1}^n X_i}{\sum_{i=1}^n n_i}\) (the sample proportion of 1s).</li>
<li>If \(X \stackrel{iid}{\sim} Poisson(\lambda t)\) then the MLE of \(\lambda\) is \(X/t\).</li>
<li>If \(X_i \stackrel{iid}{\sim} Poisson(\lambda t_i)\) then the MLE of \(\lambda\) is
\(\frac{\sum_{i=1}^n X_i}{\sum_{i=1}^n t_i}\)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-10" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>You saw 5 failure events per 94 days of monitoring a nuclear pump. </li>
<li>Assuming Poisson, plot the likelihood</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-11" style="background:;">
  <article data-timings="">
    <pre><code class="r">lambda &lt;- seq(0, 0.2, length = 1000)
likelihood &lt;- dpois(5, 94 * lambda)/dpois(5, 5)
plot(lambda, likelihood, frame = FALSE, lwd = 3, type = &quot;l&quot;, xlab = expression(lambda))
lines(rep(5/94, 2), 0:1, col = &quot;red&quot;, lwd = 3)
lines(range(lambda[likelihood &gt; 1/16]), rep(1/16, 2), lwd = 2)
lines(range(lambda[likelihood &gt; 1/8]), rep(1/8, 2), lwd = 2)
</code></pre>

<p><img src="assets/fig/unnamed-chunk-2.png" alt="plot of chunk unnamed-chunk-2"> </p>

  </article>
  <!-- Presenter Notes -->
</slide>

    <slide class="backdrop"></slide>
  </slides>
  <div class="pagination pagination-small" id='io2012-ptoc' style="display:none;">
    <ul>
      <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=1 title='Likelihood'>
         1
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=2 title='Likelihood'>
         2
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=3 title='Interpretations of likelihoods'>
         3
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=4 title='Example'>
         4
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=5 title='Example continued'>
         5
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=6 title='Plotting likelihoods'>
         6
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=7 title=''>
         7
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=8 title='Maximum likelihood'>
         8
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=9 title='Some results'>
         9
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=10 title='Example'>
         10
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=11 title=''>
         11
      </a>
    </li>
  </ul>
  </div>  <!--[if IE]>
    <script 
      src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js">  
    </script>
    <script>CFInstall.check({mode: 'overlay'});</script>
  <![endif]-->
</body>
  <!-- Load Javascripts for Widgets -->
  
  <!-- MathJax: Fall back to local if CDN offline but local image fonts are not supported (saves >100MB) -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true
      }
    });
  </script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- <script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script> -->
  <script>window.MathJax || document.write('<script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS":{imageFont:null}});<\/script><script src="../../librariesNew/widgets/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"><\/script>')
</script>
<!-- LOAD HIGHLIGHTER JS FILES -->
  <script src="../../librariesNew/highlighters/highlight.js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <!-- DONE LOADING HIGHLIGHTER JS FILES -->
   
  </html>