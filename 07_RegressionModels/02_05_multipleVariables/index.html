<!DOCTYPE html>
<html>
<head>
  <title>Multiple variables</title>
  <meta charset="utf-8">
  <meta name="description" content="Multiple variables">
  <meta name="author" content="Brian Caffo, Jeff Leek, Roger Peng">
  <meta name="generator" content="slidify" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <link rel="stylesheet" href="../../librariesNew/frameworks/io2012/css/default.css" media="all" >
  <link rel="stylesheet" href="../../librariesNew/frameworks/io2012/css/phone.css" 
    media="only screen and (max-device-width: 480px)" >
  <link rel="stylesheet" href="../../librariesNew/frameworks/io2012/css/slidify.css" >
  <link rel="stylesheet" href="../../librariesNew/highlighters/highlight.js/css/tomorrow.css" />
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->  
  
  <!-- Grab CDN jQuery, fall back to local if offline -->
  <script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../librariesNew/widgets/quiz/js/jquery.js"><\/script>')</script> 
  <script data-main="../../librariesNew/frameworks/io2012/js/slides" 
    src="../../librariesNew/frameworks/io2012/js/require-1.0.8.min.js">
  </script>
  
  

</head>
<body style="opacity: 0">
  <slides class="layout-widescreen">
    
    <!-- LOGO SLIDE -->
        <slide class="title-slide segue nobackground">
  <aside class="gdbar">
    <img src="../../assets/img/bloomberg_shield.png">
  </aside>
  <hgroup class="auto-fadein">
    <h1>Multiple variables</h1>
    <h2>Regression</h2>
    <p>Brian Caffo, Jeff Leek, Roger Peng<br/>Johns Hopkins Bloomberg School of Public Health</p>
  </hgroup>
  <article></article>  
</slide>
    

    <!-- SLIDES -->
    <slide class="" id="slide-1" style="background:;">
  <hgroup>
    <h2>Multivariable regression</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>We have an entire class on prediction and machine learning, so we&#39;ll focus on modeling.

<ul>
<li>Prediction has a different set of criteria, needs for interpretability and standards for generalizability.</li>
<li>In modeling, our interest lies in parsimonious, interpretable representations of the data that enhance our understanding of the phenomena under study.</li>
<li>A model is a lense through which to look at your data. (I attribute this quote to Scott Zeger)</li>
<li>Under this philosophy, what&#39;s the right model? Whatever model connects the data to a true, parsimonious statement about what you&#39;re studying.</li>
</ul></li>
<li>There are nearly uncontable ways that a model can be wrong, in this lecture, we&#39;ll focus on variable inclusion and exclusion.</li>
<li>Like nearly all aspects of statistics, good modeling decisions are context dependent.

<ul>
<li>A good model for prediction versus one for studying mechanisms versus one for trying to establish causal effects may not be the same.</li>
</ul></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-2" style="background:;">
  <hgroup>
    <h2>The Rumsfeldian triplet</h2>
  </hgroup>
  <article data-timings="">
    <p><em>There are known knowns. These are things we know that we know. There are known unknowns. That is to say, there are things that we know we don&#39;t know. But there are also unknown unknowns. There are things we don&#39;t know we don&#39;t know.</em> Donald Rumsfeld</p>

<p>In our context</p>

<ul>
<li>(Known knowns) Regressors that we know we should check to include in the model and have.</li>
<li>(Known Unknowns) Regressors that we would like to include in the model, but don&#39;t have.</li>
<li>(Unknown Unknowns) Regressors that we don&#39;t even know about that we should have included in the model.</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-3" style="background:;">
  <hgroup>
    <h2>General rules</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Omitting variables results in bias in the coeficients of interest - unless their regressors are uncorrelated with the omitted ones.

<ul>
<li>This is why we randomize treatments, it attempts to uncorrelate our treatment indicator with variables that we don&#39;t have to put in the model. </li>
<li>(If there&#39;s too many unobserved confounding variables, even randomization won&#39;t help you.)</li>
</ul></li>
<li>Including variables that we shouldn&#39;t have increases standard errors of the regression variables.

<ul>
<li>Actually, including any new variables increasese (actual, not estimated) standard errors of other regressors. So we don&#39;t want to idly throw variables into the model.</li>
</ul></li>
<li>The model must tend toward perfect fit as the number of non-redundant regressors approaches \(n\).</li>
<li>\(R^2\) increases monotonically as more regressors are included.</li>
<li>The SSE decreases monotonically as more regressors are included.</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-4" style="background:;">
  <hgroup>
    <h2>Plot of \(R^2\) versus \(n\)</h2>
  </hgroup>
  <article data-timings="">
    <p>For simulations as the number of variables included equals increases to \(n=100\). 
No actual regression relationship exist in any simulation</p>

<div class="rimage center"><img src="fig/unnamed-chunk-1.png" title="plot of chunk unnamed-chunk-1" alt="plot of chunk unnamed-chunk-1" class="plot" /></div>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-5" style="background:;">
  <hgroup>
    <h2>Variance inflation</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">n &lt;- 100; nosim &lt;- 1000
x1 &lt;- rnorm(n); x2 &lt;- rnorm(n); x3 &lt;- rnorm(n); 
betas &lt;- sapply(1 : nosim, function(i){
  y &lt;- x1 + rnorm(n, sd = .3)
  c(coef(lm(y ~ x1))[2], 
    coef(lm(y ~ x1 + x2))[2], 
    coef(lm(y ~ x1 + x2 + x3))[2])
})
round(apply(betas, 1, sd), 5)
</code></pre>

<pre><code>     x1      x1      x1 
0.02839 0.02872 0.02884 
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-6" style="background:;">
  <hgroup>
    <h2>Variance inflation</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">n &lt;- 100; nosim &lt;- 1000
x1 &lt;- rnorm(n); x2 &lt;- x1/sqrt(2) + rnorm(n) /sqrt(2)
x3 &lt;- x1 * 0.95 + rnorm(n) * sqrt(1 - 0.95^2); 
betas &lt;- sapply(1 : nosim, function(i){
  y &lt;- x1 + rnorm(n, sd = .3)
  c(coef(lm(y ~ x1))[2], 
    coef(lm(y ~ x1 + x2))[2], 
    coef(lm(y ~ x1 + x2 + x3))[2])
})
round(apply(betas, 1, sd), 5)
</code></pre>

<pre><code>     x1      x1      x1 
0.03131 0.04270 0.09653 
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-7" style="background:;">
  <hgroup>
    <h2>Variance inflation factors</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Notice variance inflation was much worse when we included a variable that
was highly related to <code>x1</code>. </li>
<li>We don&#39;t know \(\sigma\), so we can only estimate the increase in the actual standard error of the coefficients for including a regressor.</li>
<li>However, \(\sigma\) drops out of the relative standard errors. If one sequentially adds variables, one can check the variance (or sd) inflation for including each one.</li>
<li>When the other regressors are actually orthogonal to the regressor of interest, then there is no variance inflation.</li>
<li>The variance inflation factor (VIF) is the increase in the variance for the ith regressor compared to the ideal setting where it is orthogonal to the other regressors.

<ul>
<li>(The square root of the VIF is the increase in the sd ...)</li>
</ul></li>
<li>Remember, variance inflation is only part of the picture. We want to include certain variables, even if they dramatically inflate our variance. </li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-8" style="background:;">
  <hgroup>
    <h2>Revisting our previous simulation</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">##doesn&#39;t depend on which y you use,
y &lt;- x1 + rnorm(n, sd = .3)
a &lt;- summary(lm(y ~ x1))$cov.unscaled[2,2]
c(summary(lm(y ~ x1 + x2))$cov.unscaled[2,2],
  summary(lm(y~ x1 + x2 + x3))$cov.unscaled[2,2]) / a
</code></pre>

<pre><code>[1] 1.895 9.948
</code></pre>

<pre><code class="r">temp &lt;- apply(betas, 1, var); temp[2 : 3] / temp[1]
</code></pre>

<pre><code>   x1    x1 
1.860 9.506 
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-9" style="background:;">
  <hgroup>
    <h2>Swiss data</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">data(swiss); 
fit1 &lt;- lm(Fertility ~ Agriculture, data = swiss)
a &lt;- summary(fit1)$cov.unscaled[2,2]
fit2 &lt;- update(fit, Fertility ~ Agriculture + Examination)
fit3 &lt;- update(fit, Fertility ~ Agriculture + Examination + Education)
  c(summary(fit2)$cov.unscaled[2,2],
    summary(fit3)$cov.unscaled[2,2]) / a 
</code></pre>

<pre><code>[1] 1.892 2.089
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-10" style="background:;">
  <hgroup>
    <h2>Swiss data VIFs,</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">library(car)
fit &lt;- lm(Fertility ~ . , data = swiss)
vif(fit)
</code></pre>

<pre><code>     Agriculture      Examination        Education         Catholic Infant.Mortality 
           2.284            3.675            2.775            1.937            1.108 
</code></pre>

<pre><code class="r">sqrt(vif(fit)) #I prefer sd 
</code></pre>

<pre><code>     Agriculture      Examination        Education         Catholic Infant.Mortality 
           1.511            1.917            1.666            1.392            1.052 
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-11" style="background:;">
  <hgroup>
    <h2>What about residual variance estimation?</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Assuming that the model is linear with additive iid errors (with finite variance), we can mathematically describe the impact of omitting necessary variables or including unnecessary ones.

<ul>
<li>If we underfit the model, the variance estimate is biased. </li>
<li>If we correctly or overfit the model, including all necessary covariates and/or unnecessary covariates, the variance estimate is unbiased.</li>
<li>However, the variance of the variance is larger if we include unnecessary variables.</li>
</ul></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-12" style="background:;">
  <hgroup>
    <h2>Covariate model selection</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Automated covariate selection is a difficult topic. It depends heavily on how rich of a covariate space one wants to explore. 

<ul>
<li>The space of models explodes quickly as you add interactions and polynomial terms. </li>
</ul></li>
<li>In the prediction class, we&#39;ll cover many modern methods for traversing large model spaces for the purposes of prediction.</li>
<li>Principal components or factor analytic models on covariates are often useful for reducing complex covariate spaces.</li>
<li>Good design can often eliminate the need for complex model searches at analyses; though often control over the design is limited.</li>
<li>If the models of interest are nested and without lots of parameters differentiating them, it&#39;s fairly uncontroversial to use nested likelihood ratio tests. (Example to follow.)</li>
<li>My favoriate approach is as follows. Given a coefficient that I&#39;m interested in, I like to use covariate adjustment and multiple models to probe that effect to evaluate it for robustness and to see what other covariates knock it out.  This isn&#39;t a terribly systematic approach, but it tends to teach you a lot about the the data as you get your hands dirty.</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-13" style="background:;">
  <hgroup>
    <h2>How to do nested model testing in R</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">fit1 &lt;- lm(Fertility ~ Agriculture, data = swiss)
fit3 &lt;- update(fit, Fertility ~ Agriculture + Examination + Education)
fit5 &lt;- update(fit, Fertility ~ Agriculture + Examination + Education + Catholic + Infant.Mortality)
anova(fit1, fit3, fit5)
</code></pre>

<pre><code>Analysis of Variance Table

Model 1: Fertility ~ Agriculture
Model 2: Fertility ~ Agriculture + Examination + Education
Model 3: Fertility ~ Agriculture + Examination + Education + Catholic + 
    Infant.Mortality
  Res.Df  RSS Df Sum of Sq    F  Pr(&gt;F)    
1     45 6283                              
2     43 3181  2      3102 30.2 8.6e-09 ***
3     41 2105  2      1076 10.5 0.00021 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

    <slide class="backdrop"></slide>
  </slides>
  <div class="pagination pagination-small" id='io2012-ptoc' style="display:none;">
    <ul>
      <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=1 title='Multivariable regression'>
         1
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=2 title='The Rumsfeldian triplet'>
         2
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=3 title='General rules'>
         3
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=4 title='Plot of \(R^2\) versus \(n\)'>
         4
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=5 title='Variance inflation'>
         5
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=6 title='Variance inflation'>
         6
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=7 title='Variance inflation factors'>
         7
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=8 title='Revisting our previous simulation'>
         8
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=9 title='Swiss data'>
         9
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=10 title='Swiss data VIFs,'>
         10
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=11 title='What about residual variance estimation?'>
         11
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=12 title='Covariate model selection'>
         12
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=13 title='How to do nested model testing in R'>
         13
      </a>
    </li>
  </ul>
  </div>  <!--[if IE]>
    <script 
      src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js">  
    </script>
    <script>CFInstall.check({mode: 'overlay'});</script>
  <![endif]-->
</body>
  <!-- Load Javascripts for Widgets -->
  
  <!-- MathJax: Fall back to local if CDN offline but local image fonts are not supported (saves >100MB) -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true
      }
    });
  </script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- <script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script> -->
  <script>window.MathJax || document.write('<script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS":{imageFont:null}});<\/script><script src="../../librariesNew/widgets/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"><\/script>')
</script>
<!-- LOAD HIGHLIGHTER JS FILES -->
  <script src="../../librariesNew/highlighters/highlight.js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <!-- DONE LOADING HIGHLIGHTER JS FILES -->
   
  </html>